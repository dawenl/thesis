
%!TEX root = thesis.tex

\chapter{Background}\label{chpt:background}

\section{Probabilistic modeling and inference techniques}\label{chpt:background:sec:inference}

\subsection{Maximum \emph{a posteriori}}

\subsection{Variational inference}

\section{Recommender systems}\label{chpt:background:sec:recsys}

Making good recommendations is an important problem on the web. In the
recommendation problem, we observe how a set of users interacts with a
set of items, and our goal is to show each user a set of previously
unseen items that she will like.  Broadly speaking, recommender
systems use historical data to infer users' preferences, and then use
the inferred preferences to suggest items.  Good recommender
systems are essential as the web grows; users are overwhelmed with
choice.

\subsection{Explicit and implicit feedback} \label{chpt:background:sec:data}

Traditionally there are two modes of this problem, recommendation from
explicit data and recommendation from implicit data.  With explicit
data, users rate some items (positively, negatively, or along a
spectrum) and we can predict their missing ratings (the task of \textit{rating prediction}, popularized by the Netflix Prize\footnote{\url{http://www.netflixprize.com/}}). This is called explicit data because it is enough to only use the rated items to infer a user's
preferences. Positively rated items indicate types of items that she
likes; negatively rated items indicate items that she does not like. Explicit data is of great value, but it is often difficult to obtain. 

In implicit data, each user expresses a binary decision about items\footnote{In principle, implicit data can go beyond binary: For example, the number of times a user listened to certain songs can also be considered as implicit feedback. However, in practice we find that the binary indicator of \textit{interaction} tends to carry the most signal. }---for
example this can be clicking, purchasing, viewing---and we aim to
predict unclicked items that she would want to click on. Unlike
ratings data, implicit data is easily accessible.  While ratings data
requires action on the part of the users, implicit data is often a
natural byproduct of their behavior, e.g., browsing histories, click
logs, and past purchases. We will explore recommender systems for both implicit and explicit data in this dissertation in \Cref{chpt:expomf} and \Cref{chpt:causal_rec}, respectively.

\subsection{Collaborative filtering for recommender systems} \label{chpt:background:sec:cf}

\PP Collaborative filtering is the workhorse of recommender systems.

\PP Neighborhood-based \citep{sarwar2001item} and latent factor model \citep{koren2009matrix}.

\parhead{Matrix factorization for collaborative filtering.} User-item preference data, whether explicit or implicit, can be encoded in a user by item matrix. Throughout this dissertation, a user is indexed by $u \in \{1, \dots, U\}$, an item is indexed by $i \in \{1, \dots, I\}$, and we will refer to this user by item matrix as the \emph{click matrix} or the \emph{interaction matrix}. Given the observed entries in this matrix $\{y_{ui}: (u, i) \in \cO\}$, the recommendation task is often framed as filling in the unobserved entries.  Matrix factorization models, which infer (latent) user preferences and item attributes by factorizing the click matrix, are standard in recommender
systems \citep{koren2009matrix}. From a generative modeling perspective they
can be understood as first drawing user and item latent factors corresponding,
respectively, to user preferences and item attributes. Then drawing 
observations from a specific distribution (e.g., a Poisson
or a Gaussian) with its mean parametrized by the dot product between the user and
the item factors. Formally, Gaussian matrix factorization is \citep{mnih2007probabilistic}: 
\begin{equation} 
\begin{split}
	\boldsymbol\theta_{u} &\sim \mathcal{N}(\bzero, \lambda_\theta^{-1} \mathrm{I}_K) \quad \textrm{for } u = 1, \dots, U, \\
	\boldsymbol\beta_{i} &\sim \mathcal{N}(\bzero, \lambda_\beta^{-1} \mathrm{I}_K) \quad \textrm{for } i = 1, \dots, I, \\
	y_{ui} &\sim \mathcal{N}(\boldsymbol\theta_u^\top \boldsymbol\beta_i, \lambda_y^{-1}) \quad \textrm{for } (u, i) \in \cO, 
 \end{split}
 \label{chpt:background:eq:gmf}
 \end{equation}
where $\boldsymbol\theta_u$ and $\boldsymbol\beta_i$ represent user $u$'s latent preferences and
item $i$'s attributes respectively. We use the mean and covariance to
parametrize the Gaussian distribution. $\lambda_\theta$, $\lambda_\beta$, and
$\lambda_y$ can be treated as hyperparameters, or be given priors for a full Bayesian treatment. $\mathrm{I}_K$ stands for the identity
matrix of dimension $K$. The maximum \emph{a posteriori} estimates of the Gaussian matrix factorization model is equivalent to the solution of minimizing the squared loss between the estimated and actual preferences $\sum_{(u, i)\in \mathcal{O}} (y_{ui} - \theta_u^\top\beta_i)^2$ with $\ell_2$ regularization on the latent factors.

\parhead{Collaborative filtering for implicit data.} \Cref{chpt:background:eq:gmf} can be equally applied to both explicit and implicit data. The real difference is how to define the observed set $\cO$: For explicit data, it can simply be the user-item pairs where user $u$ has clicked on (rated) item $i$. However, we can not copy the same definition for implicit data. The reason is that the data is binary and thus, when inferring a user's preferences, we must use unclicked items (otherwise, it would be like training a classifier with only positive labels\footnote{Recommendation from implicit data is also known as one-class collaborative filtering \citep{pan2008one}.}), i.e., $\cO$ contains all the entires in the click matrix. 

Mirroring methods for explicit data, many methods treat unclicked items as those a user does not like.  But this assumption is mistaken, and overestimates the effect of the unclicked items.  Some of these
items---many of them, in large-scale settings---are unclicked because
the user didn't see them, rather than because she chose not to
click them.  This is the crux of the problem of analyzing implicit
data: we know users click on items they like, but we do not know why
an item is unclicked.

\gls{WMF}, the standard factorization model for implicit
data, selectively downweights evidence from the click
matrix~\citep{hu2008collaborative}.  \gls{WMF} uses a simple heuristic where all
unobserved user-item interactions are equally downweighted vis-a-vis the
observed interactions. Under \gls{WMF} an observation is generated from:
\begin{align*} 
y_{ui} &\sim \mathcal{N}(\boldsymbol\theta_u^\top\boldsymbol\beta_i, c^{-1}_{y_{ui}}),
\end{align*}
where the ``confidence'' $c$ is set such that $c_1 > c_0$. This dependency between a
click and itself is unorthodox; because of it \gls{WMF} is not a generative
model. As we will describe in \Cref{sec:model} we obtain a proper generative
model by adding an exposure latent variable. 

\gls{WMF} treats the collaborative filtering problem with implicit data as a
regression problem. Concretely, consumed user-item pairs are assigned a
value of one and unobserved user-item pairs are assigned a value of zero.
Bayesian personalized ranking (BPR) \citep{rendle2009bpr,
rendle2014improving} instead treats the problem as a one of ranking
consumed user-item pairs above unobserved pairs.
In a similar vein, the weighted approximate-ranking pairwise (WARP) loss
proposed in \citet{weston2011wsabie} approximately optimizes Precision@$k$. 
To deal with the non-differentiable nature of the ranking
loss, these methods typically design specific (stochastic optimization)
methods for parameter estimation.

%with closed-form
%model inference, these methods typically require specifically designed
%stochastic method for parameter estimation.   

\section{Causal inference}\label{chpt:background:sec:causal}



