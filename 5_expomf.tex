%!TEX root = thesis.tex


\chapter{Modeling User Exposure in Recommendation} \label{chpt:expomf}

In this chapter and the next chapter, we will focus on general models for recommender systems. 
Collaborative filtering analyzes user preferences for items (e.g., books,
movies, restaurants, academic papers) by exploiting the similarity patterns
across users. In implicit feedback settings, all the items, including the ones 
that a user did not consume, are taken into consideration. But this
assumption does not accord with the common sense understanding that users have
a limited scope and awareness of items. For example, a user might not have
heard of a certain paper, or might live too far away from a restaurant to
experience it. In the language of causal analysis \citep{imbens2015causal}, the
assignment mechanism (i.e., the items that a user is exposed to) is a latent
variable that may change for various user/item combinations. 
In this paper, we propose a new probabilistic approach that directly
incorporates \emph{user exposure} to items into collaborative filtering.
The exposure is modeled as a latent variable and the model infers its
value from data. In doing so, we recover one of the most successful
state-of-the-art approaches \gls{WMF} as a special case of our model
\citep{hu2008collaborative}, and provide a plug-in method for conditioning
exposure on various forms of \emph{exposure covariates} (e.g., topics in text,
venue locations). We show that our scalable inference algorithm
outperforms existing benchmarks in four different domains both with and
without exposure covariates.


\section{Introduction}
\label{chpt:expomf:sec:intro}

As motivated in \Cref{chpt:background:sec:recsys}, it is crucial to make good recommendation on the web, as users are overwhelmed with choice. In this chapter, we focus on recommendation with implicit data (see \Cref{chpt:background:sec:data} for definition). 

Existing approaches account for this by downweighting the unclicked
items.  In \gls{WMF} \citep{hu2008collaborative} the data about unclicked items are given a
lower ``confidence'', expressed through the variance of a Gaussian
random variable.  In Bayesian personalized ranking \citep{rendle2009bpr}, the unclicked items are artificially
subsampled at a lower rate in order to reduce their influence on the
estimation.  These methods are effective, but they involve heuristic
alterations to the data.

We take a direct approach to solving this problem.  We
develop a probabilistic model for recommendation called Exposure MF
(abbreviated as ExpoMF) that separately captures whether a user has been exposed to an item from
whether a user has ultimately decided to click on it.  This leads to an
algorithm that iterates between estimating the user preferences and
estimating the exposure, i.e., why the unclicked items were unclicked.
When estimating preferences, it naturally downweights the unclicked items
that it expected the user will like, because it imagines that she was not
exposed to them. 

Concretely, imagine a music listener with a strong preference for alternative
rock bands such as Radiohead. Imagine that, in a dataset, there are some
Radiohead tracks that this user has not listened to. There are different
reasons which may explain unlistened tracks  (e.g., the user has a limited
listening budget, a particular song is too recent or is unavailable from a
particular online service). According to that user's listening history these
unlistened tracks would likely make for good recommendations. In this situation
our model would assume that the user does not know about these tracks---she has
not been exposed to them---and downweight their (negative) contribution when
inferring that user's preferences.

Further, by separating the two sides of the problem, our approach
enables new innovations in implicit recommendation
models. Specifically, we can build models of users' exposure that
are guided by additional information such as item content, if
exposure to the items typically happens via search, or user/item
location, if the users and items are geographically organized. 
%Furthermore, Content Exposure MF also outperforms a model for 

As an example imagine a recommender system for diners in New York City and
diners in Las Vegas. New Yorkers are only exposed to restaurants in New York City.
From our model's perspective, unvisited restaurants in New York are therefore more 
informative in deriving a New Yorker's preferences compared to unvisited 
restaurants in Las Vegas. Accordingly for New York users our model will
upweight unvisited restaurants in New York while downweighting unvisited
Las Vegas restaurants. 

We studied our method with user listening history from a music intelligence company, clicks from a scientific e-print server, user
bookmarks from an online reference manager, and user checkins at venues from a 
location-based social network. In all cases, ExpoMF matches or surpasses
the state-of-the-art method of \gls{WMF} \citep{hu2008collaborative}. Furthermore, when
available, we use extra information to inform our user exposure model. In those
cases using the extra information outperforms the simple ExpoMF model.
Further, when using document content information our model also
outperforms a method specially developed for recommending documents using content and user click information 
\citep{wang2011collaborative}. We illustrate the
alternative-rock-listener and the New-York-dinner examples using real data fit 
with our models in \Cref{chpt:expomf:fig:expo_exp} and \Cref{chpt:expomf:fig:si}. 
Finally, we demonstrate the versatility of ExpoMF by showcasing a couple of examples which incorporate exposure from different sources (e.g., the authors of a paper, or friends in a social network). 

%We show that Exposure MF advantageously compares to the state-of-the-art
%model of \citet{hu2008collaborative} on several recommendation datasets. 

%We developed two such models and extend our inference procedures to them.  In
%their respective domains Location Exposure MF and Content Exposure MF
%outperform the simpler Exposure MF model.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "consider"
%%% End:



\section{Exposure matrix factorization}\label{sec:model}

We present exposure matrix factorization (ExpoMF). 
In \Cref{sec:model_description}, we describe the main model. 
In \Cref{sec:modeling_mu} we discuss several ways 
of incorporating external information into ExpoMF (i.e., topics from text, locations). 
%Then, in Section~\ref{sec:potential_outcomes}, we note the close similarities between our model and the potential outcomes framework for causality. 
We derive inference procedures for our model (and variants) in \Cref{sec:inference}. Finally we discuss how to make predictions given our model in \Cref{chpt:expomf:sec:pred}.

\subsection{Model description}
\label{sec:model_description}
%\PP introduce our model in a general form: the choice matrix $a_{ui} \sim \mathrm{Bernoulli}(\mu_{ui})$. Explain $a_{ui}$, connect to assignment mechanism

For every combination of users $u=1,\dots,U$ and items $i=1,\dots,I$, consider two sets of variables. The first matrix $\bA = \left\{ a_{ui} \right\}$ indicates whether user $u$ has been exposed to item $i$ (exposure matrix). The second matrix $\bY = \left\{ y_{ui} \right\}$ indicates whether or not user $u$ clicked on item $i$ (click matrix).

Whether a user is exposed to an item comes from a Bernoulli. Conditional on being exposed, user's preference comes from a Gaussian matrix factorization model, which factorizes this conditional distribution to $K$ user preferences $\theta_{i,1:K}$ and $K$ item attributes $\beta_{u,1:K}$,
\begin{equation}
	\begin{split}
	\mb\theta_{u} &\sim \cN(\bzero, \lambda_\theta^{-1} \mathrm{I}_K) \\
	\mb\beta_{i} &\sim \cN(\bzero, \lambda_\beta^{-1} \mathrm{I}_K)  \\
	a_{ui} &\sim \mathrm{Bernoulli}(\mu_{ui}) \\
	y_{ui} \g a_{ui} = 1 &\sim \cN(\mb\theta_u^\top \mb\beta_i, \lambda_y^{-1}) \\
	y_{ui} \g a_{ui} = 0 &\sim \delta_0,
	\end{split}
	\label{chpt:expomf:eq:expo_mf}
 \end{equation}
where $\delta_0$ denotes that $p(y_{ui} = 0 \g a_{ui} = 0) = 1$, and we
introduced a set of hyperparameters denoting the inverse variance
($\lambda_\theta$, $\lambda_\beta$, $\lambda_y$). $\mu_{ui}$ is the prior
probability of exposure, we discuss various ways of setting or learning it
in subsequent sections. 
A graphical representation of the model in \Cref{chpt:expomf:eq:expo_mf} is given in \Cref{fig:plate_diagram}. 

We observe the complete click matrix $\bY$. These have a special structure. When $y_{ui} > 0$, we know that $a_{ui} = 1$. When $y_{ui} = 0$, then $a_{ui}$ is latent. 
The user might have been exposed to item $i$ and decided not to click (i.e., $a_{ui}=1$, $y_{ui} = 0$); 
or she may have never seen the item (i.e., $a_{ui}=0$, $y_{ui}=0$). 
We note that since $\bY$ is usually sparse in practice, 
most $a_{ui}$ will be latent.

The model described in \Cref{chpt:expomf:eq:expo_mf}
leads to the following log joint probability\footnote{N.B., we follow the convention that $0 \log 0 = 0$ to allow the log joint to be defined when $y_{ui}>0$.} of exposures and clicks 
for user $u$ and item $i$,
\begin{equation}
\begin{split}
	\log p( & a_{ui}, y_{ui} \g \mu_{ui}, \mb\theta_u, \mb\beta_i, \lambda_y^{-1}) \\ 
	= & \log \mathrm{Bernoulli}(a_{ui} \g \mu_{ui}) + 
	a_{ui} \log \mathcal{N}(y_{ui} \g \mb\theta_u^\top \mb\beta_i, \lambda_y^{-1}) \\
	& + (1-a_{ui}) \log \mathbb{I}[y_{ui}=0], %\mathbb{I}[y_{ui} = 0],
	\end{split}
	\label{eq:a_y_joint}
\end{equation}
where $\mathbb{I}[b]$ is the indicator function that evaluates to 1 when $b$ is true, and 0 otherwise. 

What does the distribution in \Cref{eq:a_y_joint} say 
about the model's exposure beliefs when no clicks are observed? 
When the predicted preference is high 
(i.e., when $\mb\theta_u^\top \mb\beta_i$ is high) 
then the log-likelihood of no clicks $\log \mathcal{N}(0 \g \mb\theta_u^\top \mb\beta_i, \lambda^{-1}_y)$ is low and likely non-positive.
This feature penalizes the model 
for placing probability mass on $a_{ui}=1$, 
forcing us to believe that user $u$ is \emph{not} exposed to item $i$. 
(The converse argument also holds for low values of $\mb\theta_u^\top \mb\beta_i$). 
Interestingly, a low value of $a_{ui}$ 
downweights the evidence for $\mb\theta_u$ and $\mb\beta_i$ 
(this is clear by considering extreme values: 
when $a_{ui}=0$, the user and item factors do not affect the log joint in \Cref{eq:a_y_joint} at all; 
when $a_{ui}=1$, we recover standard matrix factorization). 
Like \gls{WMF} \citep{hu2008collaborative}, ExpoMF shares the same feature of selectively downweighting evidence from the click matrix. 

In ExpoMF, fixing the entries of the exposure matrix to a single value
(e.g., $a_{ui}=1, \forall u, i$) recovers Gaussian probabilistic matrix
factorization \cite{salakhutdinov2008probabilistic} (see \Cref{chpt:background:sec:mf_cf}). \gls{WMF} is also a special case of
our model which can be obtained by fixing ExpoMF's exposure matrix using the confidence $c_0$ and $c_1$ (see \Cref{chpt:background:sec:cf_implicit}).

The intuitions we developed for 
user exposure from the joint probability 
do not yet involve $\mu_{ui}$, 
the prior belief on exposure. 
As we noted earlier, 
there are a rich set of choices 
available in the modeling of $\mu_{ui}$. 
We discuss several of these next.

\begin{figure}
  \centering
  \begin{subfigure}[t]{4in}
  \centering
  \includegraphics{fig/plate_diagram.pdf}
  \caption{Exposure MF.}
  \label{fig:plate_diagram}
  \end{subfigure}
  \\
  \begin{subfigure}[t]{4in}
  \centering
  \includegraphics{fig/plate_diagram_side_info.pdf}
  \caption{Exposure MF with exposure covariates.}
  \label{fig:plate_diagram_side_info}
  \end{subfigure}
  \caption{Graphical representation of the exposure MF model (both with and without exposure covariates). The lightly shaded node $a_{ui}$ indicates that it is partially observed (i.e., it is observed when $y_{ui} = 1$ and unobserved otherwise).}
\end{figure}

\subsection{Hierarchical modeling of exposure}
\label{sec:modeling_mu}
%\subsection{Incorporating Side Information}

We now discuss methods for choosing and learning $\mu_{ui}$. 
One could fix $\mu_{ui}$ 
at some global value for all users and items, 
meaning that the user factors, item factors, and clicks 
would wholly determine exposure (conditioned on variance hyperparameters). 
One could also fix $\mu_{ui}$ for specific values of $u$ and $i$. 
This can be done when there is specific extra information 
that informs us about exposure (denoted as \emph{exposure covariates}), e.g. the location of a restaurant, the content of a paper. 
However, we found that empirical performance is highly sensitive to this choice, 
motivating the need to place models on the prior for $\mu_{ui}$ 
with flexible parameters. 

We introduce observed exposure covariates $\mbx_i$ and exposure model parameters $\mb\psi_{u}$ 
and condition $\mu_{ui} \g \mb{\psi}_{u}, \mb{x}_{i}$ 
according to some domain-specific structure. 
The extended graphical model with exposure covariates 
is shown in \Cref{fig:plate_diagram_side_info}. 
Whatever this exposure model looks like, 
conditional independence between the priors for exposure 
and the more standard collaborative filtering parameters (given exposure) 
ensures that the updates for the model we introduced in \Cref{sec:model_description}
will be the same for many popular inference procedures (e.g., expectation-maximization, variational inference, Gibbs sampling), 
making the extension to exposure covariates a plug-in procedure. 
We discuss two possible choices of exposure model next.

%-consider an observed matrix $\bY$ of implicit feedback\\
%-of size $N_u$ (the number of users) by $N_i$ (the number of items).\\
%-We use notation $y_{ui}$ to indicate a single entry in this matrix.\\
%-Start with the standard collaborative filtering\\
%-assumption that the interaction between users and items\\
%-is explained by a set of $K$-dimensional factors,\\
%-$\theta_u$ and $\beta_i$, respectively,\\
%-for users $u = 1,2,\dots,N_u$ and items $i = 1,2,\dots,N_i$.\\
%-values of $y_{ui}$ (numbers of clicks) are drawn randomly $y_{ui} \sim \mathcal{N}(\theta_u^\top \beta_i, \sigma^2)$\\
%-given variance parameter $\sigma^2$.\\
%
%-
%

\parhead{Per-item $\mu_i$.} A direct way to encode exposure is via item
popularity: if a song is popular, it is more likely that you have been
exposed to it. Therefore, we choose an item-dependent conjugate prior on
$\mu_i \sim \mathrm{Beta}(\alpha_1, \alpha_2)$. This model does not use
any external information (beyond clicks). 

\parhead{Text topics or locations as exposure covariates.} 
In the domain of recommending text documents, 
we consider the exposure covariates as the set of words 
for each document. 
In the domain of location-based recommendation, 
the exposure covariates are the locations of the venues being recommended. 
We treat both in a similar way. 

Consider a $L$-dimensional ($L$ does not necessarily equal the latent space dimension $K$ in the matrix factorization model) representation $\mbx_i$ 
of the content of document $i$ 
obtained through natural language processing (e.g., word embeddings \citep{mikolov2013distributed}, latent Dirichlet allocation \citep{blei2003latent}), 
or the position of venue $i$ obtained by first clustering all the venues in the data set 
then finding the expected assignment to $L$ clusters 
for each venue. 
In both cases, $\mbx_i$ is all positive and normalizes to 1. 
Denoting $\sigma(\cdot)$ as the sigmoid function, 
we set
\begin{equation*}
	\mu_{ui} = \sigma(\mb\psi_u^\top \mbx_i), 
\end{equation*}
where we learn the coefficients $\mb\psi_u$ 
for each user $u$. Furthermore, we can include intercepts with various levels and interactions \citep{gelman2006data}. 

How to interpret the coefficients $\mb\psi_u$? 
The first interpretation is that of logistic regression, 
where the independent variables are $\mbx_i$, 
the dependent binary variables are $a_{ui}$, 
and the coefficients to learn are $\mb\psi_u$. 
%This leads to an obvious extension: add an intercept $\mu_{ui} = \sigma(\psi_u \pi_i + c)$, 
%corresponding to hierarchical logistic regression [REF]. 

The second interpretation is from a recommender systems perspective: 
$\mb\psi_u$ represents the topics (or geographical points of interest) that a user is usually exposed to, 
restricting the choice set to documents and venues that match $\mb\psi_u$. 
For example, if the $l^\mathrm{th}$ topic represents neural networks, 
and $x_{il}$ is high, 
then the user must be an avid consumer of neural network papers 
(i.e., $\mb\psi_{ul}$ must be high) 
for the model to include an academic paper $i$ in the exposure set of $u$.
In the location domain if the $l^\mathrm{th}$ cluster represents Brooklyn, 
and $x_{il}$ is high, 
then the user must live in or visit Brooklyn often 
for the model to include venues near there in the exposure set of $u$. 


%\parhead{Side information from location.}\\
%\PP featurized location: $\mu_{ui} = \sigma(\psi_u \pi_i)$

%\subsection{Connection to Potential Outcomes Framework}

\subsection{Inference}
\label{sec:inference}
We use \gls{EM} algorithm to find the maximum \emph{a posteriori} estimates of the unknown parameters of the model (see \Cref{chpt:background:sec:em}).\footnote{There are various other inference methods we could have used, such as \gls{MCMC} \citep{neal1993probabilistic,robert2013monte} or variational inference \citep{jordan1999introduction,wainwright2008graphical}. We chose \gls{EM} for reasons of efficiency and simplicity, and find that it performs well in practice.} The algorithm is summarized in \Cref{chpt:expomf:algo:expomf}.

%\subsubsection{Inference for exposure MF.}
%\label{sec:inf_basic_model}
%Complete data log-likelihood:
%\begin{equation}
%\mathcal{L} = \sum_{u, i} \mathds{1}\{a_{ui} = 1\} \big(\log\mu + \log p(y_{ui} | \theta_u^T\beta_i)\big) + \mathds{1}\{a_{ui} = 0\} \log (1 - \mu)
%\end{equation}
The \gls{EM} inference procedure for the basic model, ExpoMF, 
can be found by writing out the full log-likelihood of the model, 
then alternating between finding the expectations of missing data (exposure)
in the E(xpectation)-step and finding maximum of the likelihood with respect to the parameters in the M(aximization)-step. 
This procedure is analytical for our model because it is conditionally conjugate, 
meaning that the posterior distribution of each random variable 
is in the same family as its prior in the model. 

Furthermore, as we mentioned in \Cref{sec:modeling_mu}, conditional independence 
between the priors for $\mu_{ui}$ and the rest of the model (given $\mu_{ui}$) 
means that the update for the latent exposure variables and user and item factors are not altered for any exposure model we use. We present these general updates first.

\parhead{E-step.}
In the E-step, we compute expectation of the exposure latent variable $\E{a_{ui}}$ for all user and item combinations ($u$, $i$) for which there are no observed clicks (recall that the presence of clicks $y_{ui}>0$ means that $a_{ui}=1$ deterministically),
\begin{equation}
\E{a_{ui} \g \mb\theta_u, \mb\beta_i, \mu_{ui}, y_{ui} = 0} = \frac{\mu_{ui} \cdot \mathcal{N}(0 | \mb\theta_u^\top\mb\beta_i, \lambda_y^{-1})}{\mu_{ui}\cdot \mathcal{N}(0 |  \mb\theta_u^\top \mb\beta_i, \lambda_y^{-1}) + (1 - \mu_{ui})}.
\label{eq:update_a}
\end{equation}
where $\mathcal{N}(0 \g \mb\theta_u^\top\mb\beta_i, \lambda_y^{-1})$ stands for the probability density function of $\mathcal{N}(\mb\theta_u^\top\mb\beta_i, \lambda_y^{-1})$ evaluated at $0$. 

\parhead{M-step.} 
%Denote $P \in [0, 1]^{U\times I}$ the posterior computed from E-step for each user-item pair (if $y_{ui} > 0$, $p_{ui} = 1$). For notational convenience, we define the concatenated user latent factors matrix $\Theta \overset{\triangle}{=} [\theta_1 | \cdots | \theta_U ]^T  \in \mathbb{R}^{U \times K}$ and item latent factors matrix $B \overset{\triangle}{=} [\beta_1 | \cdots | \beta_I ]^T  \in \mathbb{R}^{I \times K}$. Thus the update for factors is
For notational convenience, we define $p_{ui} = \E{a_{ui} \g \mb\theta_u, \mb\beta_i, \mu_{ui}, y_{ui} = 0}$ computed from the E-step. Without loss of generality, we define $p_{ui} = 1$ if $y_{ui} = 1$. The update for the latent collaborative filtering factors is:
\begin{align}
\mb\theta_u^\new &\leftarrow (\lambda_y \sum_i p_{ui} \mb\beta_i \mb\beta_i^\top +  \lambda_\theta I_K)^{-1} (\sum_i \lambda_y p_{ui} y_{ui} \mb\beta_i ) \label{eq:update_theta}\\
\mb\beta_i^\new &\leftarrow (\lambda_y \sum_u p_{ui} \mb\theta_u \mb\theta_u^\top + \lambda_\beta I_K)^{-1} (\sum_u \lambda_y p_{ui} {y}_{ui} \mb\theta_u), \label{eq:update_beta}
\end{align}
Again, this looks very similar to the \textit{alternating least squares} update of \gls{WMF}, which reveals the close connection between ExpoMF and \gls{WMF}.

\subsubsection{Inference for the exposure prior $\mu_{ui}$}
\label{sec:inf_hier_model}
We now present inference for the hierarchical variants of ExpoMF. 
% As described in \Cref{sec:modeling_mu}, conditional independence 
% between the priors for $\mu_{ui}$ and the rest of the model (given $\mu_{ui}$) 
% means that the only altered updates in hierarchical ExpoMF 
% is the update for $\mu_{ui}$, and, if applicable, its prior random variables. 
% This means that, relative to \Cref{sec:inf_basic_model}, the entire E-step is unaltered 
% and that the M-step updates to user and item factors are also the same (that is, updates in Eq.~\ref{eq:update_a},~\ref{eq:update_theta},~and~\ref{eq:update_beta} still hold). 
In particular we highlight the updates to 
$\mu_{ui}$ under the various models we presented in \Cref{sec:modeling_mu}.

\parhead{Update for per-item $\mu_{i}$.} Maximizing the log-likelihood with respect to $\mu_i$ is equivalent to finding the mode of the complete conditional $\mathrm{Beta}(\alpha_1 + \sum_u p_{ui}, \alpha_2 + U - \sum_u p_{ui})$, which is:
\begin{equation}\label{eq:mu_i}
\mu_i \leftarrow \frac{\alpha_1 + \sum_u p_{ui}- 1}{\alpha_1 + \alpha_2 + U - 2}
\end{equation}

\parhead{Update for exposure covariates (topics, location).} Setting $\mu_{ui} = \sigma(\mb\psi_u^\top \mbx_i)$, where $\mbx_i$ is given by pre-processing (topic analysis or location clustering), presents us with the challenge of maximizing the log-likelihood with respect to exposure model parameters $\mb\psi_u$. Since there is no analytical solution for the mode, we resort to following the gradients of the log-likelihood with respect to $\mb\psi_u$,
\begin{equation}
	\mb\psi_u^{\text{new}} \leftarrow \mb\psi_u + \eta \nabla_{\mb\psi_u} \mathcal{L}, %^\mathrm{(previous)}
	\label{eq:update_psi}
\end{equation}
for some learning rate $\eta$, where
\begin{equation*}
	\nabla_{\mb\psi_u} \mathcal{L} =  \frac{1}{I}\sum_i ( p_{ui} - \sigma(\mb\psi_u^\top \mbx_i))\mbx_i.
\end{equation*}

This can be computationally challenging especially for large item-set sizes $I$. Therefore, we perform (mini-batch) stochastic gradient descent: at each iteration $t$, we randomly subsample a small batch of items $B_t$ and take a noisy gradient steps:
\begin{equation} \label{eq:update_psi_sgd}
\mb\psi_u^{\text{new}} \leftarrow \mb\psi_u + \eta_t \tilde{\mb{g}}_t
\end{equation}
for some learning rate $\eta_t$, where
\begin{equation*}
\tilde{\mb{g}}_t =  \frac{1}{|B_t|}\sum_{i \in B_t} (p_{ui} - \sigma(\mb\psi_u^\top \mbx_i)) \mbx_i.
\end{equation*}

For each \gls{EM} iteration, we found it sufficient to do a single update to the
exposure model parameter $\mb\psi_u$ (as opposed to updating until it
reaches convergence). This partial M-step \citep{neal1998view} is much faster in practice. 

\begin{algorithm}
\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead 
\KwIn{Click matrix $\bY$, exposure covariates $x_{1:I}$ (topics or locations, optional)}
\KwOut{User latent factors $\mb\theta_{1:U}$, item latent factors $\mb\beta_{1:I}$, exposure priors~$\mu_{1:I}$ (for per-item $\mu_i$), OR exposure model parameters $\mb\psi_{1:U}$ (with exposure model)}
%$C \gets \emptyset$\;
Random initialization: $\mb\theta_{1:U}$, $\mb\beta_{1:I}$, $\mu_{1:I}$, OR $\mb\psi_{1:U}$\;
\While{performance on validation set increases}{
  Compute expected exposure $\bA$ (\Cref{eq:update_a})\;
  Update user factors $\mb\theta_{1:U}$ (\Cref{eq:update_theta})\;	
  Update item factors $\mb\beta_{1:I}$ (\Cref{eq:update_beta})\;
  \If{ExpoMF with per-item $\mu_i$}{
  Update priors $\mu_{i}$ (\Cref{eq:mu_i})
  }
  \If{ExpoMF with exposure model $\mu_{ui} = \sigma(\mb\psi_u^\top \mbx_i)$}{
  Update coefficients $\mb\psi_u$ (\Cref{eq:update_psi} or \Cref{eq:update_psi_sgd})
  }

}
\Return{$\mb\theta_{1:U}$, $\mb\beta_{1:I}$, $\mu_{1:I}$, OR $\mb\psi_{1:U}$}\;
\caption{{\sc Expo-ALS} Inference for ExpoMF}
\label{chpt:expomf:algo:expomf}
\end{algorithm}

\subsubsection{Complexity and implementation details}\label{chpt:expomf:sec:implmentation}

A naive implementation of the \gls{WMF} has the same complexity as ExpoMF in terms of updating the user and item factors. However, the trick that is used to speed up computations in \gls{WMF} described in \Cref{chpt:background:sec:cf_implicit} cannot be applied to ExpoMF due to the non-uniformness of the exposure latent variable $a_{ui}$. On the other hand, the factor updates are still independent across users and items. These updates can therefore easily be parallelized.

In ExpoMF's implementation, explicitly storing the exposure matrix $\bA$ is impractical for even medium-sized datasets. As an alternative, we perform the E-step on the fly: only the necessary part of the exposure matrix $\bA$ is constructed for the updates of the user/item factors and exposure priors $\mu_{ui}$. As shown in \Cref{chpt:expomf:sec:exp}, with parallelization and the on-the-fly E-step, ExpoMF can be easily fit to medium-to-large datasets.\footnote{The source code to reproduce all the experimental results is available at: \url{https://github.com/dawenl/expo-mf}.}

\subsection{Prediction} \label{chpt:expomf:sec:pred}
In matrix factorization collaborative filtering the prediction of $y_{ui}$ is given by the dot product between the inferred user and item factors $\mb\theta_u^\top\mb\beta_i$. This corresponds to the predictive density of ExpoMF $p(y_{ui} \g \bY)$ using point mass approximations to the posterior given by the \gls{EM} algorithm\footnote{This quantity is also the treatment effect $\E{y_{ui} \g a_{ui}=1, \mb\theta_u, \mb\beta_i} - \E{y_{ui} \g a_{ui}=0, \mb\theta_u, \mb\beta_i}$ in the potential outcomes framework (see \Cref{chpt:background:sec:potential}), since $a_{ui}=0$ deterministically ensures $y_{ui}=0$.}. 
However, ExpoMF can also make predictions by integrating out the uncertainty from the exposure latent variable $a_{ui}$:
\begin{equation*}
\begin{split}
\mathbb{E}_y[y_{ui} \g \mb\theta_u, \mb\beta_i] &= \mathbb{E}_a\big[\mathbb{E}_y [y_{ui} \g \mb\theta_u, \mb\beta_i, a_{ui}]\big]\\
&= \sum_{a_{ui}\in \{0, 1\}} \mathbb{P}(a_{ui}) \mathbb{E}_y [y_{ui} \g \mb\theta_u, \mb\beta_i, a_{ui}] \\
&= \mu_{ui} \cdot \mb\theta_u^\top\mb\beta_i
\end{split}
\end{equation*}
We experimented with both predictions in our study and found that the
simple dot product works better for ExpoMF with per-item $\mu_i$ while
$\E{y_{ui} \g \mb\theta_u, \mb\beta_i}$ works better for ExpoMF with exposure covariates. We provide further insights about this difference in \Cref{chpt:expomf:sec:si_doc}.


\section{Related work}
\label{chpt:expomf:sec:related}

In this section we highlight connections between ExpoMF and other
similar research directions. 


%is a special case of the model described in Eq.~\ref{chpt:expomf:eq:expo_mf}.
%we briefly compare to their approach.
%they optimize the function,
%\begin{displaymath}
%%\mathcal{L} = 
%\sum_{u, i} c_{ui} (y_{ui} - \theta_u^\top \beta_i)^2 + \lambda_\theta
%\sum_u\|\theta_u \|^2 + \lambda_\beta \sum_i \| \beta_i\|^2
%\end{displaymath}
%with respect to $\theta$ and $\beta$, where $c_{ui}$ has 
%. 

\parhead{Causal inference.} Our work borrows ideas from the field of
causal inference \citep{pearl2009causality,imbens2015causal}. Causal inference aims at understanding and
explaining the effect of one variable on another. 

One particular aim of causal inference is to answer counterfactual
questions. For example, ``would this new recommendation engine increase
user click through rate?''.  While online studies may answer such a question, they are
typically expensive even for large electronic commerce companies.
Obtaining answers to such questions using observational data alone (e.g.,
log data) is therefore of important practical
interest \citep{bottou2015counterfactual,li2010contextual,swaminathan2015counterfactual}.

We establish a connection with the potential outcome framework of
\citet{rubin1974ece}. In this framework one differentiates the assignment mechanism,
whether a user is exposed to an item, from the potential outcome, whether a
user consumes an item. In potential outcome terminology our work can thus
be understood as a form a latent assignment model. In particular, while
consumption implies exposure, we do not know which items users have 
seen but not consumed. Further the questions of interest to us,
personalized recommendation, depart from traditional work in causal
inference which aims at quantifying the effect of a particular treatment
(e.g., the efficacy of a new drug). 

%As far as we know this is the first time this connection has be
%formally established by the recommendation literature. 

\parhead{Biased CF models.} Authors have recognized that typical
observational data describing user rating items is biased toward items of
interest. Although this observation is somewhat orthogonal to our
investigation, models that emerged from this line of work share
commonalities with our approach.  Specifically, \citet{DBLP:conf/uai/MarlinZRS07,ling12response}
separate the \emph{selection model} (the exposure matrix) from the
\emph{data model} (the matrix factorization). However, their
interpretation, rooted in the theory of missing data \citep{little1986statistical}, leads to a
much different interpretation of the selection model. They hypothesize
that the value of a rating influences whether or not a user will report
the rating (this implicitly captures the effect that users mostly consume
items they like \emph{a priori}). This approach is also specific to
explicit feedback data. In contrast, we model how (the value of) the
exposure matrix affects user rating or consumption. 

\parhead{Modeling exposure with random graphs.} The user-item
interaction can also be encoded as a bipartite graph.
\citet{paquet2013one} model exposure using a hidden \emph{consider graph}.
This graph plays a similar role as our exposure variable. One important
difference is that during inference, instead of directly inferring the
posterior as in ExpoMF (which is computationally more demanding), an
approximation is developed whereby a random consider graph is
stochastically sampled.
%LC: I don't exactly understand what this means. 
%to produce roughly the same type of graphs as the observed user-item
%interaction graph as a variational approximation. 


\parhead{Exposure in other contexts.} In zero-inflated Poisson regression, a
latent binary random variable, similar to our exposure variable is introduced to ``explain away'' the structural zeros, such that the
underlying Poisson model can better capture the count data
\citep{lambert1992zero}. This type of model is common in Economics where it is used to account for overly frequent zero-valued observations.  

ExpoMF can also be considered as an instance of a spike-and-slab model \citep{ishwaran2005spike} where the ``spike'' comes from the exposure variables and the matrix factorization component forms the flat ``slab'' part. 

\parhead{Versatile CF models.} As we show in \Cref{sec:modeling_mu},
ExpoMF's exposure matrix can be used to model external information describing user
and item interactions. This is in contrast to most CF models which are
crafted to model a single type of data (e.g., document content when
recommendation scientific papers \citep{wang2011collaborative}). An exception is
factorization machines (FM) of \citet{rendle2010fm}. FM models all types of
(numeric) user, item or user-item features. FM considers the interaction
between all features and learns specific parameters for each interaction.


\section{Empirical study}
\label{chpt:expomf:sec:exp}

In this section we study the recommendation performance of ExpoMF by fitting
the model to several datasets. We provide further insights into ExpoMF's
performance by exploring the resulting model fits. We highlight that: 
\begin{itemize} 
\item ExpoMF performs comparably better than the state-of-the-art \gls{WMF}
\cite{hu2008collaborative} on four datasets representing user clicks, checkins,
bookmarks and listening behavior.
\item When augmenting ExpoMF with exposure covariates its performance is
further improved. ExpoMF with location covariates and ExpoMF with content
covariates both outperform the simpler ExpoMF with per-item $\mu_i$.
Furthermore, ExpoMF with content covariates outperforms \gls{CTR} \citep{wang2011collaborative}, a state-of-the-art
document recommendation model.  
\item Through posterior exploration we provide insights into ExpoMF's user-exposure modeling.
\end{itemize} 

\subsection{Datasets}
Throughout this study we use four medium to large-scale user-item consumption datasets from various domains: 
1) taste profile subset (TPS) of the million song dataset \citep{bertin2011million}; 2) scientific articles data from
arXiv; 3) user bookmarks from Mendeley\footnote{\url{http://mendeley.com}}; and 4) check-in
data from the Gowalla dataset \citep{cho2011friendship}. In more details:

\begin{table}
\centering
\begin{tabular}{ c c c c c  }
  \toprule
   & \textbf{TPS} & \textbf{Mendeley} & \textbf{Gowalla} & \textbf{ArXiv} \\
   \midrule
  \# of users & 221,830 & 45,293 & 57,629 & 37,893   \\
  \# of items & 22,781& 76,237 & 47,198 & 44,715 \\
  \# interactions & 14.0M &  2.4M & 2.3M & 2.5M\\
  $\%$ interactions & 0.29\% & 0.07\% & 0.09\% & 0.15\%\\
  \bottomrule 
\end{tabular}
\caption{Attributes of datasets after pre-processing. Interactions are non-zero
entries (listening counts, clicks, and checkins). \% interactions refers to the
density of the user-item click matrix ($\bY$).}
\label{chpt:expomf:tab:data}
\end{table}

\begin{itemize}
\item \emph{Taste Profile Subset (TPS):} contains user-song play counts
collected by the music intelligence company Echo
Nest.\footnote{\url{http://the.echonest.com}} We binarize the play counts and
interpret them as implicit preference. We further pre-process the dataset by
only keeping the users with at least 20 songs in their listening history and
songs that are listened to by at least 50 users. 

\item \emph{ArXiv:} contains user-paper clicks derived from log data collected
in 2012 by the arXiv pre-print server. Multiple clicks
by the same user on the same paper are considered to be a single click. We
pre-process the data to ensure that all users and items have a minimum of 10
clicks. 

\item \emph{Mendeley:} contains user-paper bookmarks as provided by 
the Mendeley service, a ``reference
manager''. The behavior data is filtered such that each
user has at least 10 papers in her library and the papers that are bookmarked
by at least 20 users are kept. In addition this dataset contains the
content of the papers which we pre-process using standard techniques to
yield a 10K words vocabulary. In \Cref{chpt:expomf:sec:si_doc} we make use of paper
content to inform ExpoMF's exposure model.  

\item \emph{Gowalla:} contains user-venue checkins from a location-based social
network. We pre-process the data such that all
users and venues have a minimum of 20 checkins. Furthermore, this dataset
also contains locations for the venues which we will use to guide 
location-based recommendation (\Cref{sec:chpt:expomf:sec:si_location}).  
\end{itemize}

The important attributes of these datasets are summarized in \Cref{chpt:expomf:tab:data}.

\subsection{Experimental setup} 
%\PP Experiment setup: split dataset to train/test/validation, hyperparameter grid search. 

For each dataset we randomly split the observed user-item interactions
into training/test/validation sets with 70/20/10 proportions. In all the experiments, the dimension 
of the latent space for collaborative filtering model $K$ is 100. The
model is trained following the inference algorithm described in
\Cref{chpt:expomf:algo:expomf}. We monitor the convergence of the algorithm using
the truncated normalized discounted cumulative gain ({NDCG@100}, see below for
details) on the validation set. Hyper-parameters for ExpoMF-based models
and baseline models are also selected according to the same criterion.

To make predictions, for each user $u$, we rank each item using its predicted
preference ${y}^*_{ui} = \mb\theta_u^\top \mb\beta_i$, $i = 1, \cdots, I$.
We then exclude items from the training and validation sets and calculate all the
metrics based on the resulting ordered list. Further when using
ExpoMF with exposure covariates we found that performance was improved by predicting missing preferences
according to $\mathbb{E}[y_{ui}|\mb\theta_u,\mb\beta_i]$ (see \Cref{chpt:expomf:sec:pred} for details).

\subsection{Performance measures}

To evaluate the recommendation performance, we report both Recall@$k$, a standard
information retrieval measure, as well as two ranking-specific
metrics: mean average precision (MAP@$k$) and
NDCG@$k$.

We denote $\text{rank}(u, i)$ as the rank of item $i$ in user $u$'s
predicted list and $\mathbf{y}_u^{\text{test}}$ as the set of items in the
heldout test set for user $u$.

\begin{itemize}
\item Recall@$k$: For each user $u$, Recall@$k$ is computed as follows:
\begin{displaymath}
\text{Recall@}k =\sum_{i\in\mathbf{y}^{\text{test}}_u} \frac{\mathbb{I}\{\text{rank}(u, i) \leq k\}}{\min(k, |\mathbf{y}_u^{\text{test}}|) }
\end{displaymath}
where $\mathbb{I}\{\cdot\}$ is the indicator function. In all our experiments we report both $k=20$ and $k=50$. This is slightly different from the metric we used in \Cref{chpt:content:sec:exp_rec}: the expression in the denominator evaluates to the minimum between $k$ and the
number of items consumed by user $u$. In this way, Recall@$k$ is normalized to have a maximum of 1. This corresponds to successfully retrieving all the relevant items in top $k$ of the list. We do not report Precision@$k$ due to the noisy nature of the implicit feedback data: even if an item $i\notin \mathbf{y}_u^{\text{test}}$, it is possible that the user will consume it in the future. This makes Precision@$k$ less interpretable since it is prone to fluctuations. 
\item MAP@$k$: Mean average precision calculates the mean of users' average precision. The (truncated) average precision for user $u$ is: 
\begin{displaymath}
  \text{Average Precision}@k = \sum_{n=1}^k \frac{\text{Precision}@n}{\min(n,|\mathbf{y}_u^{\text{test}}|)}.
\end{displaymath}
\item NDCG@$k$: Similar to the untruncated NDCG that we used in \Cref{chpt:content:sec:exp_rec}, it emphasizes the importance of the top ranks by logarithmically discounting ranks. NDCG@$k$ for each user is computed as follows:
\begin{displaymath}
\text{DCG}@k = \sum_{i=1}^k \frac{2^{rel_i} - 1}{\log_2(i + 1)}; ~ \text{NDCG}@k = \frac{\text{DCG}@k}{\text{IDCG}@k}
\end{displaymath}
IDCG$@k$ is a normalization factor that ensures NDCG lies between zero and one
(perfect ranking). In the implicit feedback case the relevance is binary:
$rel_i = 1$ if $i\in \mathbf{y}_u^{\text{test}}$, and 0 otherwise. In our
study we always report the averaged NDCG across users. 
\end{itemize}

For the ranking-based measure in all the experiments we set $k=100$ which
is a reasonable number of items to consider for a user. Results are
consistent when using other values of $k$. 
 

\subsection{Baselines}

We compare ExpoMF to \gls{WMF}, the standard
state-of-the-art method for collaborative filtering with implicit data
\citep{hu2008collaborative}. 

We also experimented with Bayesian personalized ranking (BPR)
\citep{rendle2009bpr}, a ranking model for implicit collaborative filtering which approximately optimizes the area under the ROC curve (AUC). However preliminary results were not competitive with other
approaches. BPR is trained using stochastic optimization which can be
sensible to hyper-parameter values (especially hyper-parameters related to
the optimization procedure). A more exhaustive search over hyper-parameters
could yield more competitive results. 

%In addition to this generic baseline we also compared our model to specific
%baselines. 
We describe specific baselines relevant to modeling exposure covariates
in their dedicated subsections.

\subsection{Studying ExpoMF} 
\label{chpt:expomf:sec:expomf_study}

\parhead{Empirical evaluation.} Results comparing ExpoMF to \gls{WMF} on our four
datasets are given in
\Cref{chpt:expomf:tab:cfresults}. Each metric is averaged across all the users.
We notice that ExpoMF performs comparably better than \gls{WMF} on most
datasets (the standard errors are on the order of $10^{-4}$) %\footnote{There is little point arguing about ``statistical
%significance'' because given the number of users to average over, the
%standard errors for the metrics are vanishingly small.}, 
though the difference in performance is small. In addition, higher values
of NDCG@$100$ and MAP@$100$ (even when Recall@$50$ is lower) indicate that the
top-ranked items by ExpoMF tend to be more relevant to users' interests.  

\begin{table}
\centering
\begin{tabular}{ c  c c  c c  c c  c c  }
   & \multicolumn{2}{c}{\textbf{TPS}} & \multicolumn{2}{c}{\textbf{Mendeley}} & \multicolumn{2}{c}{\textbf{Gowalla}} & \multicolumn{2}{c}{\textbf{ArXiv}} \\ \toprule
    & WMF & ExpoMF	& WMF & ExpoMF 	& WMF& ExpoMF &	 WMF & ExpoMF \\ \midrule
  Recall@20 &  0.195 &  \textbf{0.201}              & 0.128 &  \textbf{0.139}                & \textbf{0.122} & 0.118                          &  0.143 & \textbf{0.147} \\
  Recall@50 &  \textbf{0.293} &  0.286              & 0.210 & \textbf{0.221}                  & \textbf{0.192} & 0.186                         & \textbf{0.237} & 0.236 \\
  NDCG@100  &  0.255 &  \textbf{0.263}              & 0.149 & \textbf{0.159}                 & \textbf{0.118} & 0.116                         & 0.154 & \textbf{0.157} \\
  MAP@100   &  0.092 &  \textbf{0.109}             & 0.048 & \textbf{0.055}                  & \textbf{0.044} & 0.043                         & 0.051 & \textbf{0.054}\\ \bottomrule
\end{tabular}
\caption{Comparison between WMF \citep{hu2008collaborative} and ExpoMF. While
the differences in performance are generally small, ExpoMF performs comparably better than WMF across datasets.}
\label{chpt:expomf:tab:cfresults}
\end{table}


\parhead{Exploratory analysis.} We now explore the posterior distributions of the exposure latent variables of two specific users from the TSP dataset. This
exploration provides insights into how ExpoMF infers user exposure. 

The top figure of \Cref{chpt:expomf:fig:expo_exp} shows the inferred exposure latent variable
$\mathbb{E}[a_{ui}]$ corresponding to $y_{ui} = 0$ for user A.
$\mathbb{E}[a_{ui}]$ is plotted along with the empirical item popularity
(measured by number of times a song was listened to in the training set).
We also plot the interpolated per-item exposure prior $\mu_i$ 
learned using \Cref{eq:mu_i}. There is a strong relationship between song
popularity and consideration (this is true across users). User A's
training data revealed that she has only listened to songs from either
Radiohead or Interpol (both are alternative rock bands). Therefore, for
most songs, the model infers that the probability of user A considering
them is higher than the inferred prior, i.e., it is more likely that user
A did not want to listen to them (they are \emph{true zeros}). However, as
pointed out by the rectangular box, there
are a few ``outliers'' which mostly contain songs from Radiohead and
Interpol that user A did not listen to (some of them are in fact held out
in the test set). Effectively, a lower posterior $\mathbb{E}[a_{ui}]$ than
the prior indicates that the model downweights these unlistened songs
more. In contrast, \gls{WMF} downweights all songs uniformly. 

A second example is shown in the bottom figure of \Cref{chpt:expomf:fig:expo_exp}. User B mostly
listens to \emph{indie} rock bands (e.g. Florence and the Machine, Arctic
Monkeys, and The Kills). ``Dog Days are Over'' by Florence and the Machine
is the second most popular song in this dataset, behind ``Fireworks'' by
Katy Perry. These two songs correspond to the two rightmost dots on the
figure. Given the user's listening history, the model clearly
differentiates these two similarly popular songs. The fact that user B did
not listen to ``Dog Days are Over'' (again in the test set) is more likely
due to her not having been exposed to it. In contrast the model infers
that the user probably did not like ``Fireworks'' even though it is
popular.

\begin{figure}[!tbp]
  \centering
   \includegraphics[width=\textwidth]{fig/rh_fl}
   \caption{We compare the inferred posteriors of the exposure matrix for two
  users (denoted by blue dots) and compare against the prior probability for exposure (red dashed lined). On the top, user A is a fan of the bands Radiohead and Interpol. 
  Accordingly, the model downweights unlistened songs from these two
  bands. User B has broader interests and notably enjoys listening to
  the very popular band Florence and the Machine. Similarly as for user A,
  unlistened tracks of Florence and the Machine get downweighted in the
   posterior.}
  \label{chpt:expomf:fig:expo_exp}
\end{figure}


\subsection{Incorporating exposure covariates}
%\hl{LC: Add something about our model w. side-information not being for
%out-of-matrix predictions.}

%Highlight: 1) popularity overwhelms exposure MF (point to Figure). 2)
%Side-Info helps CF focus on things you have been exposed to. 

\Cref{chpt:expomf:fig:expo_exp} demonstrates that ExpoMF strongly associates user exposure to item popularity. This is partly due to the fact that the
model's prior is parametrized with a per-item term $\mu_i$. 
(This also explains why it is not a good idea to make a prediction with $\mathbb{E}[y_{ui} \g \mb\theta_u, \mb\beta_i] = \mu_{ui} \cdot \mb\theta_u^\top\mb\beta_i$ for ExpoMF without exposure covariates because it will be highly biased towards popular items.)  
Here we are interested in using exposure covariates to provide additional
information about the (likely) exposure of users to items (see
\Cref{fig:plate_diagram_side_info}). 

Recall that the role of these exposure covariates
is to allow the matrix factorization component to focus on items that the user has been exposed to. In particular this can be done
in the model by upweighting (increasing their probability of exposure)
items that users were (likely) exposed to and downweighting items that
were not. A motivating example with restaurant recommendations and New York
City versus Las Vegas diners was discussed in \Cref{chpt:expomf:sec:intro}.
%and further discussed in \Cref{sec:model}. 

%Concretely, imagine a restaurant recommender system that has
%gathered data from users in New York City and from users in Las Vegas.  The
%model assumes that New York users are exposed to restaurants in their city
%and thus upweights ``New York zeros'' and, relatively, downweights ``Las
%Vegas zeros''. This is an advantage of having access to (location) side
%information as it would be difficult for ExpoMF to learn this
%complex interaction from user behavior data alone. 

% LC: removed, mention in method. 
%This seems controversial to the claim we made about \Cref{fig:userA} and
%\Cref{fig:userB}. We want to emphasize that the role of side-information
%is to provide extra flexibility to model the user exposure.% It is up to how the model is specifically designed to suit the data and domain. 
%\hl{make sure the ``controversial'' claim is detailed in the method section}.

In the coming subsections we compare content-aware and location-aware
versions of ExpoMF which we refer to as Content ExpoMF and Location ExpoMF
respectively. Studying each model in its respective domain we demonstrate
that the exposure covariates improve the quality of the recommendations
compared to ExpoMF with per-item $\mu_i$.

%Specifically we use this side information about user-item interactions to parametrize the exposure's prior . 
%\PP We can see with only interaction, it's hard for posterior to drift off from prior (popularity) by much. Side-information can help with that.
%\PP \hl{further editing needed} The world is full of things I haven't done. collaborative filtering should focus just on the things that I ?did? do and the things that I ?could? have done but chose not to." Apply that philosophy to both location and arxiv.

%1. Location. The world is full of restaurants. Collaborative filtering should only care about the restaurants I went to, plus the restaurants I could have gone to but chose not to (e.g., in NYC). During inference, this means heavily downweighting restaurants outside of NYC that I didn't go to.

%2. arXiv. Let's say I'm a neural network nut- morning, noon, and night, I read about them. Collaborative filtering should only care about the papers I've read and the neural network papers that I didn't read (i.e., "the papers I could have read but chose not to"). That's a controversial claim, but that's what our model is saying when applied to arXiv data.

\subsubsection{Content covariates}\label{chpt:expomf:sec:si_doc}

Scientists---whether through a search engine, a personal recommendation
or other means---have a higher likelihood of being exposed to papers
specific to their own discipline. In this section we study the problem of
using the content of papers as a way to guide inference of the exposure
component of ExpoMF.

%When a user reads a scientific paper, the content of the paper will have a
%big impact on whether or not the user will enjoy it -- it is unlikely that
%a computer scientist will consider reading a paper about molecular
%biology. 

In this use case, we model the user exposure based on the topics of
articles. We use \gls{LDA} \citep{blei2003latent},
a model of document collections, to model article content. \gls{LDA} was briefly reviewed in \Cref{chpt:content:sec:ctm}.   

We use the topic proportion $\mbx_i$ learned from the Mendeley dataset as
exposure covariates. Following the notation of \Cref{sec:modeling_mu}, our
hierarchical ExpoMF is:
\begin{displaymath} \mu_{ui}= \sigma(\mb\psi_u^\top \mbx_i + \gamma_u)\end{displaymath}
where we include a per-user bias term $\gamma_u$. Under this model, a
molecular biology paper and a computer science paper that a computer
scientist has not read will likely be treated differently: the model will
consider the computer scientist has been exposed to the computer science
paper, thus higher $\mathbb{E}[a_{ui}]$, yet not to the molecular biology
paper (hence lower $\mathbb{E}[a_{ui}]$). The matrix factorization
component of the model will focus on modeling computer science papers
since that are more likely to be have been exposed. 

Our model, Content ExpoMF, is trained following the algorithm in
\Cref{chpt:expomf:algo:expomf}. For updating exposure-related model parameters
$\mb\psi_{u}$ and $\gamma_u$, we take mini-batch gradient steps with a
batch-size of 10 users and a constant step size of $0.5$ for 10 epochs.

\begin{table}
\centering
\begin{tabular}{ c c c c}
\toprule
            & ExpoMF & Content ExpoMF & \gls{CTR} \citep{wang2011collaborative} \\ \midrule
  Recall@20 & 0.139 & \textbf{0.144}         & 0.127 \\ 
  Recall@50 & 0.221 & \textbf{0.229}         & 0.210 \\ 
  NDCG@100  & 0.159 & \textbf{0.165}         & 0.150 \\ 
  MAP@100   & 0.055 & \textbf{0.056}        & 0.049 \\ 
\bottomrule 
\end{tabular}
\caption{Comparison between Content ExpoMF and ExpoMF on Mendeley. We also compare with \gls{CTR} \citep{wang2011collaborative}, a model makes use of the same additional information as Content ExpoMF. (\gls{CTR} is reviewed in \Cref{chpt:content:sec:ctm}.)}
\label{chpt:expomf:tab:si_doc_results}
\end{table}

\parhead{Study.} We evaluate the empirical performance of Content ExpoMF and report results
in \Cref{chpt:expomf:tab:si_doc_results}. We compare to \gls{CTR}, a state-of-the-art method for recommending scientific
papers \citep{wang2011collaborative} combining both \gls{LDA} and \gls{WMF}.\footnote{Note that to train \gls{CTR}
we first learned a document topic model, fixed it and then learned the
user preference model. It was suggested by its authors
that this learning procedure provided computational advantages while not hindering performance significantly \citep{wang2011collaborative}.}
We did not compare with the more recent and scalable \gls{CTPF} \citep{gopalan2014content} since the resulting
performance differences may have been the result of \gls{CTPF} Poisson
likelihood (versus Gaussian likelihood for both ExpoMF and \gls{WMF}). Both \gls{CTR} and \gls{CTPF} were reviewed in \Cref{chpt:content}.

We note that \gls{CTR}'s performance falls in-between the performance of ExpoMF
and \gls{WMF} (from \Cref{chpt:expomf:tab:data}). \gls{CTR} is particularly well suited to the
\emph{cold-start} case which is not the data regime we focus on in this
study (i.e., recall that we have only kept papers that have been
bookmarked by at least 20 users).

\Cref{chpt:expomf:fig:si} highlights the behavior of Content ExpoMF compared to that
of regular ExpoMF. Two users are selected: User A (left column) is
interested in statistical machine learning and Bayesian statistics. User B
(right column) is interested in computer systems. Neither of them have
read ``Latent Dirichlet Allocation'' (\gls{LDA}), a seminal paper that falls within user A's
interests. On the top row we show the posterior of the exposure
latent variables $\mathbb{E}[a_{ui}]$ for two users (user A and user B)
inferred from ExpoMF with per-item $\mu_i$. \gls{LDA} is shown using a white dot.
Overall both users' estimated exposures are dominated by the empirical item
popularity. 

In contrast, on the bottom row we plot the results of Content ExpoMF.
Allowing the model to use the documents' content to infer user exposure
offers greater flexibility compared to the simple ExpoMF model. 
This extra flexibility may also explain why there is an advantage in using
inferred exposure to predict missing observations (see \Cref{chpt:expomf:sec:pred}).
Namely when exposure covariates are available the model can better capture the
underlying user exposures to items. In contrast using the inferred exposure to
predict with the simple ExpoMF model performs worse.
%This can also explain why it makes sense to use $\mathbb{E}[y_{ui}]$ as
%prediction once we incorporating exposure covariates. 
%Essentially ExpoMF makes prediction by breaking down user preference into a
%two-step procedure. Therefore, when we have a side-information model that can
%better capture the potential exposure, it will be helpful to blend it in and
%make a collective prediction.

\begin{figure}
  \centering
    \includegraphics[width=\textwidth]{fig/vanilla_vs_SI}
    \caption{We compare the inferred exposure posterior of ExpoMF (top row)
    and Content ExpoMF (bottom row). On the left are the posteriors of user A
    who is interested in statistical machine learning while on the right
    user B is interested in computer system research. Neither users have
    read the ``Latent Dirichlet Allocation'' paper. ExpoMF
    infers that both users have about equal probability of having been
    exposed to it. As we discussed in \Cref{chpt:expomf:sec:expomf_study} (and demonstrated in \Cref{chpt:expomf:fig:expo_exp}) this is mostly based on the
    popularity of this paper. In contrast, Content ExpoMF infers that
    user A has more likely been exposed to this paper because of the closeness
    between that paper's content and user A's interest. Content ExpoMF
    therefore upweights the paper. Given user B's interests the paper is
    correctly downweighted by the model.}
    \label{chpt:expomf:fig:si}
\end{figure}

%We present three use-cases to incorporate side-information.
\subsubsection{Location covariates}
\label{sec:chpt:expomf:sec:si_location}

When studying the Gowalla dataset we can use venue location as exposure covariates.
%We show another use case where venue locations are treated as side information (Location ExpoMF) for user-venue check-ins from Gowalla dataset. 

Recall from \Cref{sec:modeling_mu} that location exposure covariates are created
by first clustering all venues (using $k$-means) and then finding the
representation of each venue in this clustering space. Similarly as in Content
ExpoMF (\Cref{chpt:expomf:sec:si_doc}), Location ExpoMF departs from ExpoMF:
\begin{displaymath} \mu_{ui}= \sigma(\mb\psi_u^\top \mbx_i + \gamma_u)\end{displaymath}
where $x_{ik}$ is the venue $i$'s expected assignment to cluster $k$ and
$\gamma_u$ is a per-user bias term.\footnote{We named Content ExpoMF
and Location ExpoMF differently to make it clear to the reader that they
condition on content and location features respectively. Both models are
in fact mathematically equivalent.}

%\PP Point out this is a very straightforward model, we can have user-specific length-scale $\ell_u$ (e.g., certain users tends to go further to explore while others prefer visiting the venues close by). 

\parhead{Study.} We train Location ExpoMF following the same procedure as
Content ExpoMF. We report the empirical comparison between \gls{WMF}, ExpoMF and
Location ExpoMF in \Cref{chpt:expomf:tab:si_location_results}. We note that Location
ExpoMF outperforms both \gls{WMF} and the simpler version of ExpoMF. 

\begin{table}
\centering
\begin{tabular}{c c c c}
\toprule
            & WMF & ExpoMF & Location ExpoMF \\ \midrule
  Recall@20 & 0.122 & 0.118 & \textbf{0.129} \\
  Recall@50 & 0.192 & 0.186 & \textbf{0.199} \\
  NDCG@100  & 0.118 & 0.116 & \textbf{0.125} \\
  MAP@100   & 0.044 & 0.043 & \textbf{0.048} \\
\bottomrule
\end{tabular}
\caption{Comparison between Location ExpoMF and ExpoMF with per-item
$\mu_i$ on Gowalla. Using location exposure covariates outperforms the
simpler ExpoMF and WMF according to all metrics.}
\label{chpt:expomf:tab:si_location_results}
\end{table}

For comparison purposes we also developed a simple baseline Filter\gls{WMF} which makes use of the
location covariates. Filter\gls{WMF} filters out venues recommended by \gls{WMF} that are inaccessible (too far) to the user. Since user
location is not directly available in the dataset, we estimate it using the
geometric median of all the venues the user has checked into. 
The median is preferable to the mean because it is better at handling outliers and is more likely to choose a typical visit location. 
However, the results of this simple Filter\gls{WMF} baseline are worse than the results of the
regular WMF. We attribute this performance to the fact that having a single focus of location 
is too strong an assumption to capture visit behavior of users well. 
In addition, since we randomly split the data, it is possible that a user's
checkins at city A and city B are split between the training and test set.
We leave the exploration of better location-aware baselines to future work. 


\section{Extensions}

Besides the Content and Location ExpoMF from \Cref{chpt:expomf:sec:exp}, in this section we further demonstrate the versatility of the proposed ExpoMF model by incorporating exposure from various sources: 1) authors of a paper; 2) friends in a social network. We also demonstrate the ``plug-in'' nature of ExpoMF, showing how inference can be performed without much modification from the algorithm we developed in \Cref{sec:inference}.

\subsection{Author exposure}

In \Cref{chpt:expomf:sec:si_doc}, we assume that whether or not a scientist is exposed to a particular paper depends on the content of the paper. Here we make a different assumption: the exposure is dependent on the authors who wrote the paper -- this is a reasonable assumption, as understandably more famous authors can get more attention because of their frames. 

% Each item (paper) $i$ is represented as a vector $x_i \in \{0, 1\}^A$ where $A$ is the number of unique authors. $x_{ia} = 1$ if author $a$ is included in the author list for paper $i$. 

% The generative process:
% \begin{itemize}
% \item For each user $u$, draw user latent factor $\theta_{u} \sim \mathcal{N}(0, \lambda_\theta^{-1} I_K)$.
% \item For each item $i$, draw item latent factor $\beta_{i} \sim \mathcal{N}(0, \lambda_\beta^{-1} I_K)$.
% \item For each user-item pair $(u, i)$, draw latent exposure variable $a_{ui} \sim \text{Bern}(\sigma(\psi_u^\top x_i + \gamma_u))$:
% \begin{itemize}
% \item If $a_{ui} = 0$, the implicit rating $y_{ui} = 0$.
% \item Otherwise, $y_{ui} \sim \mathcal{N}(\theta_u^\top\beta_i, \lambda_y^{-1})$.
% \end{itemize}
% \end{itemize}

% 

A straightforward model of author exposure would be to consider the author-paper matrix $\mbC \in \{0, 1\}^{A\times I}$, where $A$ is the total number of unique authors: $c_{ai} = 1$ if author $a$ is included in the author list of paper $i$ and $c_{ai} = 0$ otherwise. We treat each column $\mbc_i \in \{0, 1\}^A$ as an exposure covariates vector. Then we can fit this model in the same fashion as Content and Location ExpoMF, where we learn $\mb\psi_{1:U}$ for user's exposure to authors.  

However, there are two problems with this simple model: 1) Even though the inference is straightforward following \Cref{chpt:expomf:algo:expomf}, it is almost impractical as it requires to store and constantly update a $U\times A$ dense exposure coefficient matrix $\mb\psi_{1:U}$ where $A$ can be as large as tens of thousands. 2) More importantly, this model does not take into account the influence from co-authorship. For example, imagine Dave and John have written many papers together. If a user only read Dave's papers, then the above-mentioned exposure model will not consider a paper by John more likely to be exposed comparing to the papers from some other random authors. 

To overcome the second problem, we can learn a latent representation for each author by factorizing the author-paper matrix $\mbC$. Back to our example above, with this setup John and Dave will end up being close in this learned latent space because of the similarity among co-authors. Consequently, the user who only read Dave's papers will also have higher likelihood of being exposed to John's papers.\footnote{This could potentially help with the same author with different name spellings, which is very common in the ArXiv dataset.} 

Let's assume we have learned author latent representation $\mbx_a$ ($a = 1,\cdots, A$) from author-paper matrix $\mbC$. The author-aware version of ExpoMF (we refer to as Author ExpoMF) is specified with the following hierarchical exposure prior (following the notation of \Cref{sec:modeling_mu}): 
% The generative process:
% \begin{itemize}
% \item For each user $u$, draw user latent factor $\theta_{u} \sim \mathcal{N}(0, \lambda_\theta^{-1} I_K)$.
% \item For each item $i$, draw item latent factor $\beta_{i} \sim \mathcal{N}(0, \lambda_\beta^{-1} I_K)$.
% \item For each user-item pair $(u, i)$, draw latent exposure variable $a_{ui} \sim \text{Bern}(\mu_{ui})$:
% \begin{itemize}
% \item If $a_{ui} = 0$, the implicit rating $y_{ui} = 0$.
% \item Otherwise, $y_{ui} \sim \mathcal{N}(\theta_u^\top\beta_i, \lambda_y^{-1})$.
% \end{itemize}
% \end{itemize}
%Following the notation of \Cref{sec:modeling_mu}, the hierarchical ExpoMF is defined as:
\[\mu_{ui} = \sigma((\frac{1}{|A_i|}\sum_{a\in A_i} \mbx_a)^\top \mb\psi_u + \gamma_u),\]
where $A_i$ is the set of authors of paper $i$ and $\gamma_u$ is again a user-dependent bias term. Here we take the average of the author latent representations to account for various amount of authors per paper: for ArXiv dataset that we analyzed, the number of authors per paper ranges from one to more than 150. 

Model inference for Author Exposure is similar to that of Content and Location ExpoMF, as we can treat $\frac{1}{|A_i|}\sum_{a\in A_i} \mbx_a$ as the exposure covariates. We use the same ArXiv dataset in \Cref{chpt:expomf:sec:exp} and pre-process the author-paper matrix $\mbC$ by only keeping the authors with at least 2 papers, which gives us $A = 38,627$ unique authors. We learn the author latent representation $\mbx_a$ with the Gaussian matrix factorization (\Cref{chpt:background:sec:mf_cf}) only on the observed $1$'s in the author-paper matrix $\mbC$. 

\begin{table}
\centering
\begin{tabular}{ c c c }
\toprule
            & ExpoMF & Author ExpoMF \\ \midrule
  Recall@20 & 0.143 & \textbf{0.151}     \\ 
  Recall@50 & \textbf{0.236} & 0.231   	 \\ 
  NDCG@100  & 0.157 & \textbf{0.160}    \\ 
  MAP@100   & 0.054 & \textbf{0.058}    \\ 
\bottomrule 
\end{tabular}
\caption{Comparison between Author ExpoMF and ExpoMF on ArXiv. We can see that incorporating author exposure improves the recommendation performance over the simple ExpoMF.}
\label{chpt:expomf:tab:si_author_results}
\end{table}

\parhead{Quantitative results.} We report the recommendation performance of Author ExpoMF in \Cref{chpt:expomf:tab:si_author_results}. We also compare to ExpoMF (the results are copied from \Cref{chpt:expomf:tab:cfresults}). For Author ExpoMF, we predict the missing preferences according to $\E{y_{ui} \g \mb\theta_u, \mb\beta_i}$. As we can see, incorporating author exposure improves the metrics over the simple ExpoMF, even though the difference in performance is generally small. We note that by filtering out inactive authors, some papers will be considered having ``zero'' authors, i.e., $\mbx_a = \bzero$ for $\forall a\in A_i$. This means that its exposure will be solely dependent on the user-dependent bias term $\gamma_u$, which could be restrictive. 

\parhead{Exploratory analysis.} To help develop intuition on how Author ExpoMF helps with recommendation by making use of the author exposure, we look into a particular user who has read a couple of papers about network analysis and social networks by Mark Newman. From the dataset, we can see that Aaron Clauset has published quite a few papers with Mark Newman on the same topics, of which this user hasn't read any. The author latent representation $\mbx_a$ for Mark Newman and Aaron Clauset are very close with a cosine similarity of $0.85$. Therefore, understandably Author ExpoMF recommends some of Aaron Clauset's papers on top of the recommended list. Furthermore, among these papers also include the ones that Aaron Clauset wrote with authors other than Mark Newman. For comparison, ExpoMF does not recommend any single paper from Aaron Clauset (except the one that he co-authored with Mark Newman) among the top 50. 


\subsection{Social network exposure}

Users in a social network can be naturally influenced by their friends, e.g., we will be more likely to try out a song if a friend we trust recommends it. There have been many collaborative filtering models which exploits trust among friends in a social network \citep{ma2008sorec,ma2009learning,ma2011recommender,guo2015trustsvd,chaney2015probabilistic}. In this section, we develop a social-network-aware version of ExpoMF (Social ExpoMF) where users' exposure to items is influenced by their social friends.

Social ExpoMF takes a similar approach to SocialPF \citep{chaney2015probabilistic} with the following generative process:
\begin{equation*}
	\begin{split}
	\mb\theta_{u} &\sim \cN(\bzero, \lambda_\theta^{-1} \mathrm{I}_K) \\
	\mb\beta_{i} &\sim \cN(\bzero, \lambda_\beta^{-1} \mathrm{I}_K)  \\
	\tilde{a}_{ui} &\sim \pois(\lambda_{ui}) \\
	a_{ui} &= \mathbb{I}\{\tilde{a}_{ui} > 0\}\\
	y_{ui} \g a_{ui} = 1 &\sim \cN(\mb\theta_u^\top \mb\beta_i, \lambda_y^{-1}) \\
	y_{ui} \g a_{ui} = 0 &\sim \delta_0,
	\end{split}
	\label{chpt:expomf:eq:social_expomf}
 \end{equation*}
where $\lambda_{ui} = \sum_{v\in N(u)} \tau_{uv} y_{vi} + \gamma_u + \alpha_i$. $N(u)$ is the set of users who are social friends with user $u$. $\tau_{uv}$ can be interpreted as user $v$'s influence on user $u$, which is learned as part of the inference procedure. We also include user- and item-dependent bias terms $\gamma_u$ and $\alpha_i$. We constrain exposure coefficients $\tau_{uv}$, $\gamma_u$, and $\alpha_i$ to be nonnegative, so that the rate $\lambda_{ui}$ to the Poisson-distributed random variable $\tilde{a}_{ui}$ is also nonnegative. 

How to interpret Social ExpoMF model? If $\tau_{uv}$ is high for user $u$, that means user $u$ is more likely to be exposed to the items that user $v$ (a social friend of user $u$) clicked on. Equivalently, a small value of $\tau_{uv}$ indicates that the items user $v$ clicked on will not likely expose to user $u$. If user $u$ and $v$ do not have any social overlap, then $\tau_{uv} = 0$. It is reasonable to assume the entire coefficient matrix $\mb\tau = \{\tau_{uv}\}\in \RR_+^{U\times U}$ is very sparse in practice. Consequently, we add bias terms $\mb\gamma = \{\gamma_u\} \in \RR_+^U$ and $\mb\alpha = \{\alpha_i\} \in \RR_+^I$ to capture the user- and item-level exposure patterns beyond the influence from social friends.  

Here we use a Poisson exposure model instead of the Bernoulli-logistic model that has been applied to other ExpoMF variations. This is mostly for computational concerns, as the social network data can be computationally demanding to work with. \citet{Gopalan:2015} and \citet{chaney2015probabilistic} have demonstrated that Poisson model has the computational advantages especially on sparse data. 

% \subsection{Poisson social exposure model} 
% Alternatively, for more efficient inference, we can modify the model into the following:
% \begin{itemize}
% \item For each user $u$, draw user latent factor $\theta_{u} \sim \mathcal{N}(0, \lambda_\theta^{-1} I_K)$.
% \item For each item $i$, draw item latent factor $\beta_{i} \sim \mathcal{N}(0, \lambda_\beta^{-1} I_K)$.
% \item For each user-item pair $(u, i)$, draw latent exposure variable $\tilde{a}_{ui} \sim \text{Pois}(\sum_{v\in N(u)} \tau_{uv} y_{vi} + \gamma_u + \alpha_i)$, and define $a_{ui} = \mathbb{I}\{\tilde{a}_{ui} > 0\}$:
% \begin{itemize}
% \item If $a_{ui} = 0$, the implicit rating $y_{ui} = 0$.
% \item Otherwise, $y_{ui} \sim \mathcal{N}(\theta_u^\top\beta_i, \lambda_y^{-1})$.
% \end{itemize}
% \end{itemize}

\subsubsection{A variational EM algorithm}

The inference for Social ExpoMF is more complicated due to the truncated Poisson exposure model. We develop a variational \gls{EM} algorithm for efficient model inference, where in the E-step we compute (approximate) the posterior of $a_{ui}$ and in the M-step we update the exposure coefficients $\tau_{uv}$, $\gamma_u$, and $\alpha_i$ via maximum likelihood estimation.

If we follow the general procedure of \gls{EM} algorithm in \Cref{chpt:background:sec:em} and write down the objective function, there will be a problematic term $\log \mathbb{P}(a_{ui} = 1) = \log (1 - \me^{-\lambda_{ui}})$ which prevents us from deriving closed-form coordinate updates. To work around it, we present a model augmentation strategy.\footnote{The augmentation strategy presented here comes from an unpublished note by Matthew D. Hoffman.}

We first observe that $1 - \me^{-\lambda}$ is the \gls{CDF} of the $\mathrm{Exponential}(\lambda)$ distribution evaluated at $1$. Therefore, we can define an exponential distribution truncated at 1:
\[
\mathrm{Exponential}_1(t; \lambda) = \frac{\lambda}{1 - \me^{-\lambda}} \me^{-\lambda t}, t\in[0, 1]
\]
Furthermore, we define $\mathrm{Exponential}_1(t; 0) = \mathrm{Unif}[0, 1]$. We augment the model with 
 $t_{ui} \g a_{ui} \sim \mathrm{Exponential}_1(t_{ui}; a_{ui}\lambda_{ui})$. Now the joint log-likelihood of $a_{ui}$ and $t_{ui}$ is:
\[
\log p(a_{ui}, t_{ui}) = a_{ui} (\log \lambda_{ui} - t_{ui} \lambda_{ui}) - \lambda_{ui}(1 - a_{ui}),
\]
where the problematic term $\log (1 - \me^{-\lambda_{ui}})$ gets canceled.

\parhead{E-step.} The complete data log-likelihood is
\begin{equation*}
\mathcal{L} = \sum_{u, i} a_{ui}\log \cN(y_{ui} \g \mb\theta_u^\top\mb\beta_i, \lambda_y^{-1}) + a_{ui} (\log \lambda_{ui} - t_{ui} \lambda_{ui}) - \lambda_{ui}(1 - a_{ui}) + \mathrm{priors}.
\end{equation*}
In the E-step, we use a variational distribution $q(a_{ui}, t_{ui})$ to approximate the true posterior. Since we can compute the posterior expectation of $a_{ui}$ exactly:
\begin{equation}
\E{a_{ui} \g \mb\theta_u, \mb\beta_i, \lambda_{ui}, y_{ui} = 0} = \frac{(1 - \me^{-\lambda_{ui}}) \cdot \cN(0 | \mb\theta_u^\top\mb\beta_i, \lambda_y^{-1})}{(1 - \me^{-\lambda_{ui}})\cdot \cN(0 |  \mb\theta_u^\top \mb\beta_i, \lambda_y^{-1}) + \me^{-\lambda_{ui}}},
\label{chpt:expomf:eq:social_a}
\end{equation}
we will only specify variational distribution for $t_{ui}$ as $q(t_{ui}) = \mathrm{Exponential}_1(t_{ui}; \rho_{ui})$. Define $p_{ui} = \E{a_{ui} \g \mb\theta_u, \mb\beta_i, \lambda_{ui}, y_{ui} = 0}$ and without loss of generality, we set $p_{ui} = 1$ if $y_{ui} > 0$. We tune the variational parameters $\mb\rho = \{\rho_{ui}\} \in \RR_+^{U\times I}$ to optimize the variational objective (\gls{ELBO}) for $t_{ui}$:
\[
\cL^\textrm{VI}_{ui} = -p_{ui}\mathbb{E}_q[t_{ui}] \lambda_{ui} + \rho_{ui} \mathbb{E}_q[t_{ui}] - \log\rho_{ui} + \log(1 - \me^{-\rho_{ui}}) + \const
\]
where the necessary expectation is $\mathbb{E}_q[t_{ui}] = \frac{1}{\rho_{ui}} - \frac{1}{\me^{\rho_{ui}} - 1}$. Take the derivative of \gls{ELBO} with respect to $\rho_{ui}$ and set it to $0$, we get the following updates for the variational parameters:
\begin{equation}
\rho_{ui} \leftarrow p_{ui}\lambda_{ui}
\label{chpt:expomf:eq:social_rho}
\end{equation}

\parhead{M-step.}  The objective in the M-step is the expected complete data log-likelihood under the variational distribution:
\begin{equation*}
\mathbb{E}_q[\mathcal{L}] = \sum_{u, i} p_{ui} \log \cN(y_{ui} \g \mb\theta_u^\top\mb\beta_i, \lambda_y^{-1}) + p_{ui} (\log\lambda_{ui}- \mathbb{E}_q[t_{ui}] \lambda_{ui}) - \lambda_{ui}(1 - p_{ui}) + \const.
\end{equation*}
The updates for collaborative filtering latent factors $\mb\theta_u$ and $\mb\beta_i$ are identical to all the previous models (\Cref{eq:update_theta} and \Cref{eq:update_beta}) because of the conditional independence between the exposure prior and the matrix factorization part of the model (given exposure). 

The updates for exposure coefficients $\tau_{uv}$, $\gamma_u$, and $\alpha_i$ are more difficult because of the problematic term $\log \lambda_{ui} = \log (\sum_{v\in N(u)} \tau_{uv} y_{vi} + \gamma_u + \alpha_i)$. We follow the standard strategy to lower bound it via Jensen's inequality:
\begin{align*}
\log(\sum_{v\in N(u)} \tau_{uv} y_{vi} + \gamma_u + \alpha_i) &\geq \sum_{v \in N(u)} \phi^{\tau}_{uiv} (\log\tau_{uv}y_{vi} - \log \phi_{uiv}^\tau) \\
&+ \phi^\gamma_{ui} (\log \gamma_{u} - \log\phi^\gamma_{ui}) + \phi^\alpha_{ui} (\log \alpha_{i} - \log\phi^\alpha_{ui})
\end{align*}
where $\phi^\tau_{uiv} \geq 0$, $\phi^\gamma_{ui} \geq 0$, $\phi^\alpha_{ui} \geq 0$, and $\sum_{v\in N(u)} \phi^\tau_{uiv} + \phi^\gamma_{ui} + \phi^\alpha_{ui} = 1$. To tighten the lower bound, we update $\phi^\tau_{uiv}=\frac{\tau_{uv}y_{vi}}{\lambda_{ui}}$, $\phi^\gamma_{ui} = \frac{\gamma_u}{\lambda_{ui}}$, and $\phi^\alpha_{ui} = \frac{\alpha_i}{\lambda_{ui}}$. After lower-bounding the objective, we take the gradients with respect to $\tau_{uv}$, $\gamma_u$, and $\alpha_i$ and set them to $0$, which leads to the following multiplicative updates:
\begin{equation}
\begin{split}
\tau_{uv} &\leftarrow \frac{\sum_i \phi_{uiv}^\tau p_{ui}}{\sum_i y_{vi}\big(1 - p_{ui}(1 - \mathbb{E}_q[t_{ui}])\big)}\\
\gamma_{u} &\leftarrow \frac{\sum_i \phi_{ui}^\gamma p_{ui}}{\sum_i \big(1 - p_{ui} (1 - \mathbb{E}_q[t_{ui}])\big)}\\
\alpha_{i} &\leftarrow \frac{\sum_u \phi_{ui}^\alpha p_{ui}}{\sum_u \big(1 - p_{ui} (1 - \mathbb{E}_q[t_{ui}])\big)}
\end{split}
\label{chpt:expomf:eq:social_mstep}
\end{equation}
These updates closely resemble those of \gls{NMF} with generalized \gls{KL}-divergence loss function \citep{seung2001algorithms}. The full algorithm for Social ExpoMF is summarized in \Cref{chpt:expomf:algo:social_expomf}. In actual implementation, we perform on-the-fly E-step, similar to what was described in \Cref{chpt:expomf:sec:implmentation}, for both $a_{ui}$ and $t_{ui}$, as well as parallelization when updating both latent factors ($\mb\theta_{1:U}, \mb\beta_{1:I}$) and exposure coefficients ($\mb\tau$, $\mb\gamma$, $\mb\alpha$). This enables Social ExpoMF to tractably analyze large-scale user-item interaction data with social networks. 

\begin{algorithm}
\DontPrintSemicolon % Some LaTeX compilers require you to use \dontprintsemicolon instead 
\KwIn{Click matrix $\bY$, social network $N(u)$ for $u = 1, \dots, U$}
\KwOut{User latent factors $\mb\theta_{1:U}$, item latent factors $\mb\beta_{1:I}$, exposure coefficients $\mb\tau$, $\mb\gamma$, and $\mb\alpha$}
%$C \gets \emptyset$\;
Random initialization: $\mb\theta_{1:U}$, $\mb\beta_{1:I}$, $\mb\tau$, $\mb\gamma$, $\mb\alpha$\;
\While{performance on validation set increases}{
  Compute expected exposure $\mbP = \{p_{ui}\}$ (\Cref{chpt:expomf:eq:social_a})\;
  Update variational parameter $\mb\rho = \{\rho_{ui}\}$ (\Cref{chpt:expomf:eq:social_rho})\;
  Update user factors $\mb\theta_{1:U}$ (\Cref{eq:update_theta})\;	
  Update item factors $\mb\beta_{1:I}$ (\Cref{eq:update_beta})\;
  Update exposure coefficients $\mb\tau$, $\mb\gamma$, and $\mb\alpha$ (\Cref{chpt:expomf:eq:social_mstep})\;
}
\Return{$\mb\theta_{1:U}$, $\mb\beta_{1:I}$, $\mb\tau$, $\mb\gamma$, $\mb\alpha$}\;
\caption{{\sc Social-Expo-ALS} Inference for Social ExpoMF}
\label{chpt:expomf:algo:social_expomf}
\end{algorithm}

\parhead{Data.} We evaluate Social ExpoMF on Douban dataset \citep{ma2011recommender}. Douban (douban.com) is a Chinese social service where users
record ratings for music, movies, and books. It contains 129K users and 57K items with 16M user-item interactions in the form of ratings on a 1-5 scale. The social network is undirected (i.e., if user $v$ is user $u$'s social friend, then the reverse is true) with 1.3M network connections. Following the experimental setup in \citet{chaney2015probabilistic}, we remove network connections where the users have no items in common. Furthermore, we binarize the explicit ratings by only keeping ratings greater than or equal to 4 and treat them as implicit preferences. 

\parhead{Quantitative results.} We evaluate the empirical performance of Social ExpoMF and report results in \Cref{chpt:expomf:tab:si_social_results}. We compare to the ExpoMF with per-item $\mu_i$ exposure prior. We can see that Social ExpoMF outperforms ExpoMF except on MAP@$100$. This indicates that incorporating exposure based on social network provides additional benefits on top of simple popularity-based exposure model. Unfortunately due to privacy reasons, most of the public user-item interaction datasets with social network do not have meta-data information about users and/or items, which prevents us from exploring the resulting model fit.   

\begin{table}
\centering
\begin{tabular}{ c c c }
\toprule
            & ExpoMF & Social ExpoMF \\ \midrule
  Recall@20 & 0.205 & \textbf{0.208}     \\ 
  Recall@50 & 0.306 & \textbf{0.320}   	 \\ 
  NDCG@100  & 0.225 & \textbf{0.230}    \\ 
  MAP@100   & \textbf{0.087} & 0.086    \\ 
\bottomrule 
\end{tabular}
\caption{Comparison between Social ExpoMF and ExpoMF on Douban dataset. We can see that incorporating social network exposure improves the recommendation performance over the simple ExpoMF.}
\label{chpt:expomf:tab:si_social_results}
\end{table}

\section{Summary}

%\PP Causal analysis.
%
%\PP Apply directly for explicit feedback.
%
%\PP time since item is available can be important especially for things like arXiv. 
%
%\PP Model combination 


In this chapter, we presented a novel collaborative filtering mechanism
that takes into account user exposure to items. 
In doing so, we theoretically justify existing approaches that 
downweight unclicked items for recommendation, 
and provide an extendable framework 
for specifying more elaborate models of exposure based on logistic regression. 
In empirical studies we found 
that the additional flexibility of our model 
helps it outperform existing approaches to 
matrix factorization on four datasets from various domains. We also demonstrate the versatility of our model by incorporating other sources of exposure, e.g., the authors of a paper, or the friends in a social network. 

There are several promising avenues for future work. 
Consider a reader who keeps himself up to date with the ``what's new'' pages 
of a website, or 
a tourist visiting a new city looking for a restaurant recommendation. 
The exposure processes are more dynamic in these scenarios 
and may be different during training and test time. 
We therefore seek new ways to capture exposure that include 
ever more realistic assumptions about how users interact with items. 

Finally, we would like to evaluate our proposed model in a more realistic
setting, e.g., in an online environment with user interactions. It
would be instructive to evaluate the performance of ExpoMF in environments
where it may be possible to observe items which users have been exposed
to.

%The evaluation conducted in this paper does not take user
%exposure to item into consideration -- all the metrics consider
%non-responsive data to be irrelevant. 
%
%Therefore, it is hard to pinpoint
%the benefit of explicitly modeling user exposure. 
%
%Furthermore, with the
%proposed model, we can compare two different types of recommendation: a
%relevant and exposed item versus a relevant but unexposed item. The user
%may have found the exposed item anyway, but the recommendation can provide
%true benefit by surfacing the unexposed item. 

